behaviors:
  Clicker:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 10000
      learning_rate: 0.0003
      learning_rate_schedule: linear
      beta: 0.0075
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 1
    max_steps: 20000000
    time_horizon: 30
    summary_freq: 10000
    keep_checkpoints: 50
    checkpoint_interval: 500000
    threaded: true
    network_settings:
      vis_encoder_type: simple
      normalize: true
      hidden_units: 64
      num_layers: 2
#      memory:
#        sequence_length: 16
#        memory_size: 32
    reward_signals:
      extrinsic:
        strength: 1.0
        gamma: 0.99
#      gail:
#        gamma: 0.99
#        strength: 0.75
#        network_settings:
#          normalize: true
#          hidden_units: 64
#          num_layers: 2
#          vis_encode_type: simple
#        learning_rate: 0.0001
#        use_actions: false
#        use_vail: false
#        demo_path: C:\Users\marke\repos\ml-agents\config\1.demo
#    behavioral_cloning:
#      demo_path: C:\Users\marke\repos\ml-agents\config\1.demo
#      steps: 1000000
#      strength: 0.5
#      samples_per_update: 0
#      batch_size: 128
#      num_epoch: 1
env_settings:
  env_path: C:\Users\marke\repos\ml-agents\Builds\CursorNoObs\UniversalController
  base_port: 5005
  num_envs: 5
  seed: -1
engine_settings:
  time_scale: 60
checkpoint_settings:
  run_id: quick4
  #initialize_from: unloadAssetsLOL
  #load_model: false
  #resume: true
  #force: false
  #train_model: false
  #inference: false
debug: false
torch_settings:
  device: cuda
environment_parameters:
  #decision_period: 2
  environments_per_unity_process: 5
  multi_scene: 0
